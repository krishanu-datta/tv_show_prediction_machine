{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import relevant packages\n",
    "import pandas as pd\n",
    "import urllib.request as urllib\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assign imdb list of shows to variable\n",
    "tv_list_url = 'https://www.imdb.com/list/ls085347170/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read imdb url of list of shows\n",
    "html = urllib.urlopen(tv_list_url)\n",
    "soup = BeautifulSoup(html.read())\n",
    "\n",
    "## select the actual list of shows in url\n",
    "lister = soup.find(\"div\", {\"class\": \"lister\"})\n",
    "items = lister.find_all(\"div\", {\"class\":\"lister-item-content\"})\n",
    "\n",
    "## add show page urls to a seperate list\n",
    "a_tags = []\n",
    "for i in items:\n",
    "    a_tags.append(i.find(\"a\")['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## declare empty lists for all the data that will be collected\n",
    "ratings = []\n",
    "rating_counts = []\n",
    "titles = []\n",
    "level = []\n",
    "length = []\n",
    "genre_1 = []\n",
    "genre_2 = []\n",
    "genre_3 = []\n",
    "start_years = []\n",
    "episodes = []\n",
    "top_ep = []\n",
    "sec_ep = []\n",
    "thd_ep = []\n",
    "popularity = []\n",
    "awards_1 = []\n",
    "awards_2 = []\n",
    "\n",
    "## loop through each url in the show page url list\n",
    "for url in a_tags:\n",
    "    ## read the url\n",
    "    show = 'https://www.imdb.com' + url\n",
    "    html = urllib.urlopen(show)\n",
    "    soup = BeautifulSoup(html.read())\n",
    "    \n",
    "    ## locate specific parts of the page that will be scraped\n",
    "    title_bar = soup.find(\"div\", {\"class\":\"title_bar_wrapper\"})\n",
    "    subtext = soup.find(\"div\", {\"class\":\"subtext\"})\n",
    "    article = soup.find(\"div\", {\"id\":\"titleDetails\"})\n",
    "    mini_article = soup.find(\"div\", {\"id\":\"top-rated-episodes-rhs\"})\n",
    "    review_bar = soup.find(\"div\", {\"class\":\"titleReviewBarSubItem\"})\n",
    "    awards_bar = soup.find(\"div\", {\"id\":\"titleAwardsRanks\"})\n",
    "\n",
    "    ## scrape title bar for ratings\n",
    "    if title_bar.find(\"span\",{\"itemprop\":\"ratingValue\"}) is not None:\n",
    "        ratings.append(float(title_bar.find(\"span\",{\"itemprop\":\"ratingValue\"}).text))\n",
    "    else:\n",
    "        ratings.append(\"N/A\")\n",
    "        \n",
    "    ## scrape title bar for rating counts\n",
    "    if title_bar.find(\"span\",{\"itemprop\":\"ratingCount\"}) is not None:\n",
    "        rating_counts.append(int(title_bar.find(\"span\",{\"itemprop\":\"ratingCount\"}).text.replace(\",\",\"\")))\n",
    "    else:\n",
    "        rating_counts.append(\"N/A\")\n",
    "\n",
    "    ## scrape show title from page\n",
    "    titles.append(title_bar.h1.text.strip())\n",
    "\n",
    "    ## scrape title bar for TV rating \n",
    "    if title_bar.find(\"div\",{\"class\":\"subtext\"}) is not None:\n",
    "        if title_bar.find(\"div\",{\"class\":\"subtext\"}).text.split(\"\\n\")[1].strip() != \"\":\n",
    "            level.append(title_bar.find(\"div\",{\"class\":\"subtext\"}).text.split(\"\\n\")[1].strip())\n",
    "        else:\n",
    "            level.append(\"N/A\")\n",
    "    else:\n",
    "        level.append(\"N/A\")\n",
    "\n",
    "    ## declare new genre list (reset for every show)\n",
    "    genre_list = []\n",
    "    \n",
    "    ## add all genres on page into genre list \n",
    "    for i in range(0, len(subtext.find_all(\"a\")) - 1):\n",
    "        genre_list.append(subtext.find_all(\"a\")[i].text)\n",
    "\n",
    "    ## if show has a genre, add it as genre #1\n",
    "    if len(genre_list) > 0:\n",
    "        genre_1.append(genre_list[0])\n",
    "    else:\n",
    "        genre_1.append(\"N/A\")\n",
    "        \n",
    "    ## if show has more than one genre, add it as genre #2\n",
    "    if len(genre_list) > 1:\n",
    "        genre_2.append(genre_list[1])\n",
    "    else:\n",
    "        genre_2.append(\"N/A\")\n",
    "    \n",
    "    ## if show has more than two genres, add it as genre #3\n",
    "    if len(genre_list) > 2:\n",
    "        genre_3.append(genre_list[2])\n",
    "    else:\n",
    "        genre_3.append(\"N/A\")\n",
    "\n",
    "    ## add the start year of show from page (cleaned)\n",
    "    raw_start = subtext.find_all(\"a\")[len(subtext.find_all(\"a\")) - 1]\n",
    "    start_years.append(int(raw_start.text.split(\"(\")[1].split(\"â€“\")[0].replace(\")\\n\",\"\")))\n",
    "\n",
    "    ## scrape number of episodes from episodes heading\n",
    "    if soup.find(\"a\",{\"class\":\"bp_item\"}) is not None:\n",
    "        section = soup.find(\"a\",{\"class\":\"bp_item\"})\n",
    "        episodes.append(int(section.find(\"span\",{\"class\":\"bp_sub_heading\"}).text.split()[0]))\n",
    "    else:\n",
    "        episodes.append(\"N/A\")\n",
    "        \n",
    "    ## scrape length of episode from bottom info section\n",
    "    if article.find(\"time\") is not None:\n",
    "        length.append(int(article.find(\"time\").text.split()[0]))\n",
    "    elif title_bar.find(\"time\") is not None:\n",
    "        length.append(int(title_bar.find(\"time\").text.split(\"\\n\")[1].strip()[0:2]))\n",
    "    else:\n",
    "        length.append(\"N/A\")\n",
    "\n",
    "    ## scrape top three episode ratings from right mini article bar\n",
    "    if mini_article is not None:\n",
    "        top_eps = mini_article.find_all(\"span\",{\"class\":\"ipl-rating-star__rating\"})\n",
    "        top_ep.append(top_eps[0].text)\n",
    "        sec_ep.append(top_eps[23].text)\n",
    "        thd_ep.append(top_eps[46].text)\n",
    "    else:\n",
    "        top_ep.append(None)\n",
    "        sec_ep.append(None)\n",
    "        thd_ep.append(None)\n",
    "\n",
    "    ## scape popularity from review bar\n",
    "    if review_bar is not None:\n",
    "        popularity.append(int(review_bar.find(\"span\", {\"class\": \"subText\"}).text.split()[0].replace(\",\",\"\")))\n",
    "    else:\n",
    "        popularity.append(4000)\n",
    "\n",
    "    ## scrape awards from awards bar\n",
    "    if awards_bar is not None:\n",
    "        blurbs = awards_bar.find_all(\"span\",{\"class\":\"awards-blurb\"})\n",
    "        if len(blurbs) > 1:\n",
    "            awards_1.append(\" \".join(blurbs[0].text.split()))\n",
    "            awards_2.append(\" \".join(blurbs[1].text.split()))\n",
    "        elif len(blurbs) > 0:\n",
    "            awards_1.append(\"N/A\")\n",
    "            awards_2.append(\" \".join(blurbs[0].text.split()))\n",
    "        else:\n",
    "            awards_1.append(\"N/A\")\n",
    "            awards_2.append(\"N/A\")\n",
    "            \n",
    "    else:\n",
    "        awards_1.append(\"N/A\")\n",
    "        awards_2.append(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create shows dataframe and assign lists of scraped data to dataframe columns\n",
    "shows = pd.DataFrame()\n",
    "shows[\"title\"] = titles\n",
    "shows[\"rating\"] = ratings\n",
    "shows[\"rating_count\"] = rating_counts\n",
    "shows[\"length\"] = length\n",
    "shows[\"level\"] = level\n",
    "shows[\"genre_1\"] = genre_1\n",
    "shows[\"genre_2\"] = genre_2\n",
    "shows[\"genre_3\"] = genre_3\n",
    "shows[\"start_year\"] = start_years\n",
    "shows[\"episodes\"] = episodes\n",
    "shows[\"top_ep\"] = top_ep\n",
    "shows[\"sec_ep\"] = sec_ep\n",
    "shows[\"thd_ep\"] = thd_ep\n",
    "shows[\"popularity\"] = popularity\n",
    "shows[\"awards_1\"] = awards_1\n",
    "shows[\"awards_2\"] = awards_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make new dataframe with columns to be one hot encoded (categorical variables)\n",
    "features = shows.iloc[:, 4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one hot encode the categorical data and put into a dataframe with column names\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "encoded_df = encoder.fit_transform(features)\n",
    "features_df = pd.DataFrame(encoded_df, columns = encoder.get_feature_names())\n",
    "features_df = features_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join the newly created columns to the original dataframe\n",
    "shows = shows.join(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop shows with lack of top episode data\n",
    "shows = shows.dropna(subset=['top_ep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## manually bin the episode length data into five bins\n",
    "shows['quick'] = np.where(shows['length']<20, 1, 0)\n",
    "shows['short'] = np.where((shows['length']>19.9) & (shows['length']<35), 1, 0)\n",
    "shows['medium'] = np.where((shows['length']>34.9) & (shows['length']<45), 1, 0)\n",
    "shows['long'] = np.where((shows['length']>44.9) & (shows['length']<65), 1, 0)\n",
    "shows['series'] = np.where(shows['length']>64.9, 1, 0)\n",
    "\n",
    "## group the one hot encoded genres into their true genre\n",
    "shows['Action'] = np.where(shows['x1_Action'] | shows['x2_Action'] | shows['x3_Action'], 1, 0)\n",
    "shows['Adventure'] = np.where(shows['x1_Adventure'] | shows['x2_Adventure'] | shows['x3_Adventure'], 1, 0)\n",
    "shows['Animation'] = shows['x1_Animation']\n",
    "shows['Biography'] = shows['x1_Biography']\n",
    "shows['Comedy'] = np.where(shows['x1_Comedy'] | shows['x2_Comedy'] | shows['x3_Comedy'], 1, 0)\n",
    "shows['Crime'] = np.where(shows['x1_Crime'] | shows['x2_Crime'] | shows['x3_Crime'], 1, 0)\n",
    "shows['Drama'] = np.where(shows['x1_Drama'] | shows['x2_Drama'] | shows['x3_Drama'], 1, 0)\n",
    "shows['Family'] = np.where(shows['x2_Family'] | shows['x3_Family'], 1, 0)\n",
    "shows['Fantasy'] = np.where(shows['x2_Fantasy'] | shows['x3_Fantasy'], 1, 0)\n",
    "shows['Horror'] = np.where(shows['x2_Horror'] | shows['x3_Horror'], 1, 0)\n",
    "shows['Mystery'] = np.where(shows['x2_Mystery'] | shows['x3_Mystery'], 1, 0)\n",
    "shows['Romance'] = np.where(shows['x2_Romance'] | shows['x3_Romance'], 1, 0)\n",
    "shows['Short'] = shows['x2_Short']\n",
    "shows['Sport'] = shows['x2_Sport']\n",
    "shows['Music'] = shows['x3_Music']\n",
    "shows['Sci-Fi'] = shows['x3_Sci-Fi']\n",
    "shows['Thriller'] = shows['x3_Thriller']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import csv of user-rated scores for each of shows\n",
    "target = pd.read_csv('targets.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge shows dataframe with dataframe of user inputted ratings\n",
    "shows.title.astype(str)\n",
    "target.title.astype(str)\n",
    "shows = shows.merge(target, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export final data to dataframe\n",
    "shows.to_csv('shows.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
